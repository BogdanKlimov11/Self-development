{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xw7YkEefehWo"
      },
      "source": [
        "# Домашнее задание. Классификация изображений\n",
        "\n",
        "Сегодня вам предстоить помочь телекомпании FOX в обработке их контента. Как вы знаете, сериал \"Симпсоны\" идет на телеэкранах более 25 лет, и за это время скопилось очень много видеоматериала. Персоонажи менялись вместе с изменяющимися графическими технологиями, и Гомер Симпсон-2018 не очень похож на Гомера Симпсона-1989. В этом задании вам необходимо изображения классифицировать персонажей, проживающих в Спрингфилде. Думаю, нет смысла представлять каждого из них в отдельности.\n",
        "\n",
        "Конкурс на kaggle: https://www.kaggle.com/competitions/journey-springfield\n",
        "\n",
        "\n",
        " ![alt text](https://vignette.wikia.nocookie.net/simpsons/images/5/5a/Spider_fat_piglet.png/revision/latest/scale-to-width-down/640?cb=20111118140828)\n",
        "\n",
        "## Данные\n",
        "Данные для выполнения этого задания можно скачать на Kaggle, а также по [ссылке](https://drive.google.com/file/d/1RxBQiZgRAfio2tWhEE7lzZ6IaJzLheH1/view?usp=sharing).\n",
        "Вам предоставляются следующие данные:\n",
        "* train -- обучающая выборка, на которой вы обучите свою модель\n",
        "* testset -- тестовая выборка, предсказание на которой вам необходимо сдать на Stepik, чтобы получить баллы.\n",
        "* sampleSubmission.csv -- пример посылки.\n",
        "\n",
        "Обратите внимание, что баллы за это задание выставляются при отправке вашей посылки на Stepik! Для этого мы сделали там отдельный шаг. При этом, на Kaggle задание, конечно, тоже можно отправлять, если вам это удобно. Баллы за задание при отправке в контест на Kaggle и в шаг на Stepik должны совпадать.\n",
        "\n",
        "\n",
        "## Метрика оценивания\n",
        "Зачёт задания будет происходить по качеству (F1-score), которого вы достигнете на тестовой выборке (public leaderboard) при сдаче задания в конкурс. Максимальное количество баллов за задание равняется 15. В отличие от обычных конкурсов на kaggle, в этом конкурсе в зачёт идёт ваш результат на публичной части датасета.\n",
        "\n",
        "Критерии оценки следующие:\n",
        "\n",
        "* 0.97: 15 баллов\n",
        "* 0.96: 14 баллов\n",
        "* 0.95: 13 баллов\n",
        "* ...\n",
        "* 0.84: 2 балла\n",
        "* 0.83: 1 балл\n",
        "\n",
        "Обратите внимание, что баллы за это задание выставляются при отправке вашей посылки на Stepik!\n",
        "\n",
        "## Советы по выполнению\n",
        "\n",
        "Используйте все полученные знания, в том числе навыки обучения свёрточных нейросетей, чтобы добиться наилучшего качества. Рекомендуем активно использовать GPU на Google Colab, поскольку так свёрточные нейросети будут учиться во много раз быстрее (скорее всего, у себя на процессоре вы не сможете  обучить даже простую CNN).\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oG47vhLxKNln"
      },
      "source": [
        "### Установка зависимостей"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ITX8q-BMkKu"
      },
      "source": [
        "!pip install -U torch torchvision"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWgcwKwCLBfr"
      },
      "source": [
        "# we will verify that GPU is enabled for this notebook\n",
        "# following should print: CUDA is available!  Training on GPU ...\n",
        "#\n",
        "# if it prints otherwise, then you need to enable GPU:\n",
        "# from Menu > Runtime > Change Runtime Type > Hardware Accelerator > GPU\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "if not train_on_gpu:\n",
        "    print('CUDA is not available.  Training on CPU ...')\n",
        "else:\n",
        "    print('CUDA is available!  Training on GPU ...')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import PIL\n",
        "print(PIL.PILLOW_VERSION)"
      ],
      "metadata": {
        "id": "57bAlZ3ojtVb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Данные\n",
        "\n",
        "Скачаем и распакуем данные. Если gdown не работает, скачайте данные с kaggle и добавьте их в директорию вручную."
      ],
      "metadata": {
        "id": "ITwvfT7CsUmx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1RxBQiZgRAfio2tWhEE7lzZ6IaJzLheH1"
      ],
      "metadata": {
        "id": "ohjLIACVk-ZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRGt7YicMxYI"
      },
      "source": [
        "!unzip journey-springfield.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2dg3IHMMo-s"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvWhlkiRMxih"
      },
      "source": [
        "!nvidia-smi\n",
        "torch.cuda.is_available()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BD_8gK6PmgXk"
      },
      "source": [
        "В нашем тесте будет 990 картнок, для которых вам будет необходимо предсказать класс."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naD6xsZzMxrC"
      },
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "from skimage import io\n",
        "\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "\n",
        "from torchvision import transforms\n",
        "from multiprocessing.pool import ThreadPool\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "\n",
        "from matplotlib import colors, pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# в sklearn не все гладко, чтобы в colab удобно выводить картинки\n",
        "# мы будем игнорировать warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore', category=DeprecationWarning)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTdzMtgJP15N"
      },
      "source": [
        "# разные режимы датасета\n",
        "DATA_MODES = ['train', 'val', 'test']\n",
        "# все изображения будут масштабированы к размеру 224x224 px\n",
        "RESCALE_SIZE = 224\n",
        "# работаем на видеокарте\n",
        "DEVICE = torch.device(\"cuda\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYFeKUzfy572"
      },
      "source": [
        "https://jhui.github.io/2018/02/09/PyTorch-Data-loading-preprocess_torchvision/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ecnkB2xK1aE"
      },
      "source": [
        "Ниже мы исспользуем враппер над датасетом для удобной работы. Вам стоит понимать, что происходит с LabelEncoder и  с torch.Transformation.\n",
        "\n",
        "ToTensor конвертирует  PIL Image с параметрами в диапазоне [0, 255] (как все пиксели) в FloatTensor размера (C x H x W) [0,1] , затем производится масштабирование:\n",
        "$input = \\frac{input - \\mu}{\\text{standard deviation}} $, <br>       константы - средние и дисперсии по каналам на основе ImageNet\n",
        "\n",
        "\n",
        "Стоит также отметить, что мы переопределяем метод __getitem__ для удобства работы с данной структурой данных.\n",
        " Также используется LabelEncoder для преобразования строковых меток классов в id и обратно. В описании датасета указано, что картинки разного размера, так как брались напрямую с видео, поэтому следуем привести их к одному размер (это делает метод  _prepare_sample)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cj32U5iTQUe4"
      },
      "source": [
        "class SimpsonsDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Датасет с картинками, который паралельно подгружает их из папок\n",
        "    производит скалирование и превращение в торчевые тензоры\n",
        "    \"\"\"\n",
        "    def __init__(self, files, mode):\n",
        "        super().__init__()\n",
        "        # список файлов для загрузки\n",
        "        self.files = sorted(files)\n",
        "        # режим работы\n",
        "        self.mode = mode\n",
        "\n",
        "        if self.mode not in DATA_MODES:\n",
        "            print(f\"{self.mode} is not correct; correct modes: {DATA_MODES}\")\n",
        "            raise NameError\n",
        "\n",
        "        self.len_ = len(self.files)\n",
        "\n",
        "        self.label_encoder = LabelEncoder()\n",
        "\n",
        "        if self.mode != 'test':\n",
        "            self.labels = [path.parent.name for path in self.files]\n",
        "            self.label_encoder.fit(self.labels)\n",
        "\n",
        "            with open('label_encoder.pkl', 'wb') as le_dump_file:\n",
        "                  pickle.dump(self.label_encoder, le_dump_file)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len_\n",
        "\n",
        "    def load_sample(self, file):\n",
        "        image = Image.open(file)\n",
        "        image.load()\n",
        "        return image\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # для преобразования изображений в тензоры PyTorch и нормализации входа\n",
        "        transform = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ])\n",
        "        x = self.load_sample(self.files[index])\n",
        "        x = self._prepare_sample(x)\n",
        "        x = np.array(x / 255, dtype='float32')\n",
        "        x = transform(x)\n",
        "        if self.mode == 'test':\n",
        "            return x\n",
        "        else:\n",
        "            label = self.labels[index]\n",
        "            label_id = self.label_encoder.transform([label])\n",
        "            y = label_id.item()\n",
        "            return x, y\n",
        "\n",
        "    def _prepare_sample(self, image):\n",
        "        image = image.resize((RESCALE_SIZE, RESCALE_SIZE))\n",
        "        return np.array(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_odtTEzcaWH"
      },
      "source": [
        "def imshow(inp, title=None, plt_ax=plt, default=False):\n",
        "    \"\"\"Imshow для тензоров\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt_ax.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt_ax.set_title(title)\n",
        "    plt_ax.grid(False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUhzOq1zRJil"
      },
      "source": [
        "TRAIN_DIR = Path('train/simpsons_dataset')\n",
        "TEST_DIR = Path('testset/testset')\n",
        "\n",
        "train_val_files = sorted(list(TRAIN_DIR.rglob('*.jpg')))\n",
        "test_files = sorted(list(TEST_DIR.rglob('*.jpg')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmPhhKKlRyCF"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_val_labels = [path.parent.name for path in train_val_files]\n",
        "train_files, val_files = train_test_split(train_val_files, test_size=0.25, \\\n",
        "                                          stratify=train_val_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAimOLjSQGTh"
      },
      "source": [
        "val_dataset = SimpsonsDataset(val_files, mode='val')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmKSdyv1b7PD"
      },
      "source": [
        "Давайте посмотрим на наших героев внутри датасета."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltitWp3lXAZt"
      },
      "source": [
        "fig, ax = plt.subplots(nrows=3, ncols=3,figsize=(8, 8), \\\n",
        "                        sharey=True, sharex=True)\n",
        "for fig_x in ax.flatten():\n",
        "    random_characters = int(np.random.uniform(0,1000))\n",
        "    im_val, label = val_dataset[random_characters]\n",
        "    img_label = \" \".join(map(lambda x: x.capitalize(),\\\n",
        "                val_dataset.label_encoder.inverse_transform([label])[0].split('_')))\n",
        "    imshow(im_val.data.cpu(), \\\n",
        "          title=img_label,plt_ax=fig_x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpN9lSi4QVGt"
      },
      "source": [
        "Можете добавить ваши любимые сцены и классифицировать их. (веселые результаты можно кидать в чат)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6YcZk8vQR47"
      },
      "source": [
        "### Построение нейросети\n",
        "\n",
        "Запустить данную сеть будет вашим мини-заданием на первую неделю, чтобы было проще участвовать в соревновании.\n",
        "\n",
        "Данная архитектура будет очень простой и нужна для того, чтобы установить базовое понимание и получить простенький сабмит на Kaggle\n",
        "\n",
        "<!-- Здесь вам предлагается дописать сверточную сеть глубины 4/5.  -->\n",
        "\n",
        "*Описание слоев*:\n",
        "\n",
        "\n",
        "\n",
        "1. размерность входа: 3x224x224\n",
        "2.размерности после слоя:  8x111x111\n",
        "3. 16x54x54\n",
        "4. 32x26x26\n",
        "5. 64x12x12\n",
        "6. выход: 96x5x5\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PJcWAhuji-i"
      },
      "source": [
        "# Очень простая сеть\n",
        "class SimpleCnn(nn.Module):\n",
        "\n",
        "    def __init__(self, n_classes):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=8, kernel_size=3),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2)\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2)\n",
        "        )\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2)\n",
        "        )\n",
        "        self.conv4 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2)\n",
        "        )\n",
        "        self.conv5 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=64, out_channels=96, kernel_size=3),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2)\n",
        "        )\n",
        "\n",
        "        self.out = nn.Linear(96 * 5 * 5, n_classes)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.conv5(x)\n",
        "\n",
        "        x = x.view(x.size(0), -1)\n",
        "        logits = self.out(x)\n",
        "        return logits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2mk7MNtcUhJ"
      },
      "source": [
        "def fit_epoch(model, train_loader, criterion, optimizer):\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "    processed_data = 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs = inputs.to(DEVICE)\n",
        "        labels = labels.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        preds = torch.argmax(outputs, 1)\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "        processed_data += inputs.size(0)\n",
        "\n",
        "    train_loss = running_loss / processed_data\n",
        "    train_acc = running_corrects.cpu().numpy() / processed_data\n",
        "    return train_loss, train_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_CD9--hcUjs"
      },
      "source": [
        "def eval_epoch(model, val_loader, criterion):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "    processed_size = 0\n",
        "\n",
        "    for inputs, labels in val_loader:\n",
        "        inputs = inputs.to(DEVICE)\n",
        "        labels = labels.to(DEVICE)\n",
        "\n",
        "        with torch.set_grad_enabled(False):\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            preds = torch.argmax(outputs, 1)\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "        processed_size += inputs.size(0)\n",
        "    val_loss = running_loss / processed_size\n",
        "    val_acc = running_corrects.double() / processed_size\n",
        "    return val_loss, val_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaxYIwB3cUmX"
      },
      "source": [
        "def train(train_files, val_files, model, epochs, batch_size):\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    history = []\n",
        "    log_template = \"\\nEpoch {ep:03d} train_loss: {t_loss:0.4f} \\\n",
        "    val_loss {v_loss:0.4f} train_acc {t_acc:0.4f} val_acc {v_acc:0.4f}\"\n",
        "\n",
        "    with tqdm(desc=\"epoch\", total=epochs) as pbar_outer:\n",
        "        opt = torch.optim.Adam(model.parameters())\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            train_loss, train_acc = fit_epoch(model, train_loader, criterion, opt)\n",
        "            print(\"loss\", train_loss)\n",
        "\n",
        "            val_loss, val_acc = eval_epoch(model, val_loader, criterion)\n",
        "            history.append((train_loss, train_acc, val_loss, val_acc))\n",
        "\n",
        "            pbar_outer.update(1)\n",
        "            tqdm.write(log_template.format(ep=epoch+1, t_loss=train_loss,\\\n",
        "                                           v_loss=val_loss, t_acc=train_acc, v_acc=val_acc))\n",
        "\n",
        "    return history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6G7qbYqcUpL"
      },
      "source": [
        "def predict(model, test_loader):\n",
        "    with torch.no_grad():\n",
        "        logits = []\n",
        "\n",
        "        for inputs in test_loader:\n",
        "            inputs = inputs.to(DEVICE)\n",
        "            model.eval()\n",
        "            outputs = model(inputs).cpu()\n",
        "            logits.append(outputs)\n",
        "\n",
        "    probs = nn.functional.softmax(torch.cat(logits), dim=-1).numpy()\n",
        "    return probs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzwhB4K3dQOC"
      },
      "source": [
        "n_classes = len(np.unique(train_val_labels))\n",
        "simple_cnn = SimpleCnn(n_classes).to(DEVICE)\n",
        "print(\"we will classify :{}\".format(n_classes))\n",
        "print(simple_cnn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bo3UND5RdgVg"
      },
      "source": [
        "Запустим обучение сети."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDkcxZ1kfD4a"
      },
      "source": [
        "if val_dataset is None:\n",
        "    val_dataset = SimpsonsDataset(val_files, mode='val')\n",
        "\n",
        "train_dataset = SimpsonsDataset(train_files, mode='train')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDXoR8PIdfLD"
      },
      "source": [
        "history = train(train_dataset, val_dataset, model=simple_cnn, epochs=2, batch_size=64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qMAdL_BduXZ"
      },
      "source": [
        "Построим кривые обучения"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ryD_9yFdfNr"
      },
      "source": [
        "loss, acc, val_loss, val_acc = zip(*history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpQDWGkfdfQ5"
      },
      "source": [
        "plt.figure(figsize=(15, 9))\n",
        "plt.plot(loss, label=\"train_loss\")\n",
        "plt.plot(val_loss, label=\"val_loss\")\n",
        "plt.legend(loc='best')\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gr9lRCJNNDfD"
      },
      "source": [
        "### Ну и что теперь со всем этим делать?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSe0nQ-dJ8uy"
      },
      "source": [
        "![alt text](https://www.indiewire.com/wp-content/uploads/2014/08/the-simpsons.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5k0UGeTNaQX"
      },
      "source": [
        "Хорошо бы понять, как сделать сабмит.\n",
        "У нас есть сеть и методы eval у нее, которые позволяют перевести сеть в режим предсказания. Стоит понимать, что у нашей модели на последнем слое стоит softmax, которые позволяет получить вектор вероятностей  того, что объект относится к тому или иному классу. Давайте воспользуемся этим."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8PlF6o0N9O1"
      },
      "source": [
        "def predict_one_sample(model, inputs, device=DEVICE):\n",
        "    \"\"\"Предсказание, для одной картинки\"\"\"\n",
        "    with torch.no_grad():\n",
        "        inputs = inputs.to(device)\n",
        "        model.eval()\n",
        "        logit = model(inputs).cpu()\n",
        "        probs = torch.nn.functional.softmax(logit, dim=-1).numpy()\n",
        "    return probs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pY_OoLoVO_9V"
      },
      "source": [
        "random_characters = int(np.random.uniform(0,1000))\n",
        "ex_img, true_label = val_dataset[random_characters]\n",
        "probs_im = predict_one_sample(simple_cnn, ex_img.unsqueeze(0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caivVFeAN9SY"
      },
      "source": [
        "idxs = list(map(int, np.random.uniform(0,1000, 20)))\n",
        "imgs = [val_dataset[id][0].unsqueeze(0) for id in idxs]\n",
        "\n",
        "probs_ims = predict(simple_cnn, imgs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-0pRdHnQQKM"
      },
      "source": [
        "label_encoder = pickle.load(open(\"label_encoder.pkl\", 'rb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNMFc7sfQh1a"
      },
      "source": [
        "y_pred = np.argmax(probs_ims,-1)\n",
        "\n",
        "actual_labels = [val_dataset[id][1] for id in idxs]\n",
        "\n",
        "preds_class = [label_encoder.classes_[i] for i in y_pred]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVePL0-BKHrF"
      },
      "source": [
        "Обратите внимание, что метрика, которую необходимо оптимизировать в конкурсе --- f1-score. Вычислим целевую метрику на валидационной выборке."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_h-9dDWsKGU-"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "f1_score(actual_labels, y_pred, average='micro')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds_class"
      ],
      "metadata": {
        "id": "eqTo91lMrMDi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxB9pfPfdCHr"
      },
      "source": [
        "Сделаем визуализацию,  чтобы посмотреть, насколько сеть уверена в своих ответах. Можете исспользовать это, чтобы отлаживать правильность вывода."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVjq4EC5ZZE7"
      },
      "source": [
        "import matplotlib.patches as patches\n",
        "from matplotlib.font_manager import FontProperties\n",
        "\n",
        "fig, ax = plt.subplots(nrows=3, ncols=3,figsize=(12, 12), \\\n",
        "                        sharey=True, sharex=True)\n",
        "for fig_x in ax.flatten():\n",
        "    random_characters = int(np.random.uniform(0,1000))\n",
        "    im_val, label = val_dataset[random_characters]\n",
        "    img_label = \" \".join(map(lambda x: x.capitalize(),\\\n",
        "                val_dataset.label_encoder.inverse_transform([label])[0].split('_')))\n",
        "\n",
        "\n",
        "\n",
        "    imshow(im_val.data.cpu(), \\\n",
        "          title=img_label,plt_ax=fig_x)\n",
        "\n",
        "    actual_text = \"Actual : {}\".format(img_label)\n",
        "\n",
        "    fig_x.add_patch(patches.Rectangle((0, 53),86,35,color='white'))\n",
        "    font0 = FontProperties()\n",
        "    font = font0.copy()\n",
        "    font.set_family(\"fantasy\")\n",
        "    prob_pred = predict_one_sample(simple_cnn, im_val.unsqueeze(0))\n",
        "    predicted_proba = np.max(prob_pred)*100\n",
        "    y_pred = np.argmax(prob_pred)\n",
        "\n",
        "    predicted_label = label_encoder.classes_[y_pred]\n",
        "    predicted_label = predicted_label[:len(predicted_label)//2] + '\\n' + predicted_label[len(predicted_label)//2:]\n",
        "    predicted_text = \"{} : {:.0f}%\".format(predicted_label,predicted_proba)\n",
        "\n",
        "    fig_x.text(1, 59, predicted_text , horizontalalignment='left', fontproperties=font,\n",
        "                    verticalalignment='top',fontsize=8, color='black',fontweight='bold')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hO9OLOMqIXRV"
      },
      "source": [
        "Попробуйте найти те классы, которые сеть не смогла расспознать. Изучите данную проблему, это понадобится в дальнейшем."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEWTL6jgdh7L"
      },
      "source": [
        "### Submit на Kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrjQ6cxHIGtk"
      },
      "source": [
        "![alt text](https://i.redd.it/nuaphfioz0211.jpg)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UTbU0Zbc6Hb"
      },
      "source": [
        "test_dataset = SimpsonsDataset(test_files, mode=\"test\")\n",
        "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=64)\n",
        "probs = predict(simple_cnn, test_loader)\n",
        "\n",
        "\n",
        "preds = label_encoder.inverse_transform(np.argmax(probs, axis=1))\n",
        "test_filenames = [path.name for path in test_dataset.files]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rTtbV1teD2k"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yw0zZ-Hdd89s"
      },
      "source": [
        "import pandas as pd\n",
        "my_submit = pd.read_csv(\"sample_submission.csv\")\n",
        "my_submit.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIYaqa20iYTL"
      },
      "source": [
        "# TODO: сделайте сабмит (это важно, если Вы не справляетесь, но дошли до этой ячейки, то сообщите в чат и Вам помогут)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rdlyMKtiYe2"
      },
      "source": [
        "my_submit.to_csv('simple_cnn_baseline.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3M9SQZ7MuUq"
      },
      "source": [
        "## Приключение?\n",
        "\n",
        "А теперь --- самое интересное. Мы сделали простенькую сверточную сеть и смогли отправить сабмит, но получившийся скор нас явно не устраивает. Надо с этим что-то сделать.\n",
        "\n",
        "Несколько улучшейни для нашей сети, которые наверняка пришли Вам в голову:\n",
        "\n",
        "\n",
        "*  Учим дольше и изменяем гиперпараметры сети\n",
        "*  learning rate, batch size, нормализация картинки и вот это всё\n",
        "*  Кто же так строит нейронные сети? А где пулинги и батч нормы? Надо добавлять\n",
        "*  Ну разве Адам наше все? [adamW](https://www.fast.ai/2018/07/02/adam-weight-decay/) для практика, [статейка для любителей](https://openreview.net/pdf?id=ryQu7f-RZ) (очень хороший анализ), [наши ](https://github.com/MichaelKonobeev/adashift/) эксперименты для заинтересованных.\n",
        "\n",
        "* Ну разве это deep learning? Вот ResNet и Inception, которые можно зафайнтьюнить под наши данные, вот это я понимаю (можно обучить в колабе, а можно и [готовые](https://github.com/Cadene/pretrained-models.pytorch) скачать).\n",
        "\n",
        "* Данных не очень много, можно их аугментировать и  доучититься на новом датасете\n",
        "\n",
        "\n",
        "Надеюсь, у Вас получится!"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iuOPG6R-sJo3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}