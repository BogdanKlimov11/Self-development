{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChQCezLlL15s"
      },
      "source": [
        "# Домашнее задание. Композиции алгоритмов\n",
        "В этом домашнем задании вам предстоит обучить два вида композиций алгоритмов: бэггинг и бустинг.\n",
        "\n",
        "## Постановка задачи\n",
        "Вам предлагается решить задачу бинарной классификации, а именно построить алгоритм, определяющий превысит ли средний заработок человека порог $50k. Каждый объект выборки — человек, для которого известны следующие признаки:\n",
        " - age\n",
        " - workclass\n",
        " - fnlwgt\n",
        " - education\n",
        " - education-num\n",
        " - marital-status\n",
        " - occupation\n",
        " - relationship\n",
        " - race\n",
        " - sex\n",
        " - capital-gain\n",
        " - capital-loss\n",
        " - hours-per-week\n",
        "\n",
        "## Метрика качества\n",
        "В качестве целевой метрики мы будем использовать ROC-AUC. Об этой метрике мы говорили в модуле о метриках. Как вы помните, для измерения ROC-AUC требуются вероятности принадлежности к классам. Для решающих деревьев вероятность принадлежности к классу вычисляется как доля объектов из обучающей выборки в соответствующем листе. Для алгоритма, который принимает решение взвешенным голосованием, вероятность вычисляется как среднее взвешенное значение вероятностей по всем алгоритмам в композиции.\n",
        "\n",
        "## Ход работы\n",
        "* Первым делом вы произведете загрузку и обработку данных. В частности, вам необходимо будет закодировать категориальные признаки с помощью One-hot encoding.\n",
        "* Сначала мы построим для нашей задачи обычный случайный лес и измерим его качество. Мы подберем оптимальный гиперпараметр \"глубина дерева\" для случайного леса.\n",
        "* Далее мы обучим алгоритм градиентного бустинга с помощью библиотеки Catboost. Catboost --- это библиотека для градиентного бустинга, которая автоматически обрабатывает категориальные признаки. Поэтому для этого пункта вам нужно будет использовать не One-hot признаки, а изначальные категориальные признаки.\n",
        "\n",
        "## Оценивание\n",
        "В этом домашнем задании данные разделены на две части:\n",
        "* [`data_train.csv`](https://drive.google.com/file/d/1qKakViWhNT1yTiM66V9hxADAVCYTL0PO/view?usp=share_link). Для этих данных вам известно значение целевой переменной. Эти данные вы будете использовать для обучения.\n",
        "* [`data_scoring.csv`](https://drive.google.com/file/d/1tguHTZm9-sUwTRzqAEuqLRUzKHqkvVmQ/view?usp=share_link). На этих данных вы должны будете применить готовую модель, а затем сдать результаты в Stepik. Вам необходимо будет сдать результат работы двух моделей: случайного леса и градиентного бустинга.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFdz-yifdnoA"
      },
      "source": [
        "## Часть 1. Загрузка и обработка данных\n",
        "Загрузка данных будет состоять из следующих шагов:\n",
        "* Загрузка из файла;\n",
        "* Работа с пропущенными значениями;\n",
        "* Выделение целевой переменной;\n",
        "* Разбиение данных на вещественные и категориальные;\n",
        "* One-hot кодирование категориальных данных;\n",
        "* Разбиение данных на train и test.\n",
        "\n",
        "Затем все эти шаги (кроме последнего) необходимо будет применить к `data_scoring`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fd1ZpmkBdm4t"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1qKakViWhNT1yTiM66V9hxADAVCYTL0PO #эта команда скачивает файл data_train.csv и помещает его в корневую директорию Colab. Очень удобно!"
      ],
      "metadata": {
        "id": "GCBvvmxkezaa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7F0Q9Q2v_vKL"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('data_train.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U7z3LvVjemi6"
      },
      "outputs": [],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zM8GRr8Eeiaa"
      },
      "outputs": [],
      "source": [
        "data[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r73oSpt7gJ2J"
      },
      "source": [
        "### Задание\n",
        "Проведите с данными необходимые операции:\n",
        "\n",
        "* Замените все знаки \"?\" на `np.nan`.\n",
        "* Найдите все столбцы со значениями NaN. Напечатайте их названия.\n",
        "* Выделите вектор ответов. Закодируйте правильные ответы 0 и 1:\n",
        "    * '<=50K' -> 0;\n",
        "    * '>50K' -> 1.\n",
        "* Сохраните их в отдельную переменную `y` типа `np.array`.\n",
        "* Удалите из data правильные ответы."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mXlICdKqgdX9"
      },
      "outputs": [],
      "source": [
        "data = # ВАШ КОД"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Вопрос**. В каких колонках присутствуют пропущенные значения?"
      ],
      "metadata": {
        "id": "PPUP7ZiDTbOP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ytnQP7QAglE3"
      },
      "outputs": [],
      "source": [
        "# Найдите колонки с пропущенными значениями\n",
        "<ВАШ КОД>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cf5JyNBZgwlt"
      },
      "outputs": [],
      "source": [
        "# ВАШ КОД\n",
        "y = #ВАШ КОД. Выделите целевую переменную\n",
        "y = y.astype(np.int32, copy=False)\n",
        "y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPD9ajVrg1BR"
      },
      "source": [
        "Удалим ответы из data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I01IPnPjg3FF"
      },
      "outputs": [],
      "source": [
        "data = data.drop('>50K,<=50K', 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlnToxmFhqE9"
      },
      "source": [
        "**Вопрос**. Какие из признаков являются вещественными?\n",
        "\n",
        "Выделите вещественные и категориальные признаки."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "18laWWWzenxm"
      },
      "outputs": [],
      "source": [
        "real_columns = [<ВАШ КОД>]\n",
        "\n",
        "real_data = data[real_columns]\n",
        "real_data[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "92_XZLWWhzOv"
      },
      "outputs": [],
      "source": [
        "cat_columns = [<ВАШ КОД>]\n",
        "\n",
        "cat_data = data[cat_columns]\n",
        "cat_data[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pczwiJKliLFF"
      },
      "source": [
        "### Задание\n",
        "Выделите One-hot признаки из данных с помощю объекта `OneHotEncoder` из модуля `sklearn.preprocessing`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aECoFnirKuxo"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZpH5pTkViDQy",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "ohe = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
        "one_hot_data = #ВАШ КОД. Выделите one-hot признаки. Используйте метод fit_transform\n",
        "one_hot_data = pd.DataFrame(one_hot_data, index=cat_data.index)\n",
        "one_hot_data[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-df8f5Kngx3"
      },
      "source": [
        "Наконец, разобьем данные на train и test в соотношении 70:30."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bhOsxa7-ntza"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_data, test_data, train_real_data, test_real_data, \\\n",
        "train_cat_data, test_cat_data, train_one_hot_data, test_one_hot_data, \\\n",
        "y_train, y_test = train_test_split(data, real_data,\n",
        "                                   cat_data, one_hot_data,\n",
        "                                   y, train_size=0.7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSz6Zi14Kuxp"
      },
      "source": [
        "### Задание\n",
        "Проделайте все то же самые операции для scoring_data.\n",
        "* Загрузите данные из файла data_scoring.csv;\n",
        "* Замените \"?\" на `np.nan`;\n",
        "* Выделите числовые и категориальные данные;\n",
        "* Закодируйте категориальные данные с помощью уже созданного `ohe`. Новый объект класса `OneHotEncoding` создавать не нужно. Используйте метод `ohe.transform`."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1tguHTZm9-sUwTRzqAEuqLRUzKHqkvVmQ"
      ],
      "metadata": {
        "id": "_jM3gw9TfQ5I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qEu_LMMdKuxp"
      },
      "outputs": [],
      "source": [
        "scoring_data = pd.read_csv('data_scoring.csv')\n",
        "\n",
        "scoring_data = <ВАШ КОД> #Обработайте пропущенные значения\n",
        "scoring_real_data = #ВАШ КОД. Выделите числовые колонки\n",
        "scoring_cat_data = #ВАШ КОД. Выделите категориальные колонки\n",
        "scoring_one_hot_data = #ВАШ КОД. Выделите ohe-признаки. Не забудьте создать pd.DataFrame"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEqwTZ56nD5t"
      },
      "source": [
        "## Часть 2. Обучение случайного леса\n",
        "Мы будем использовать модель `RandomForestClassifier` из `sklearn.ensemble`. Вам предстоит подобрать для случайного леса оптимальный параметр глубины. Количество деревьев в этом задании мы будем использовать постоянным и равным 100.\n",
        "\n",
        "Выбор параметра мы будем производить с помощью кросс-валидации на 5 фолдов, используя метод `cross_val_score` из `sklearn.model_selection`. Затем мы обучим окончательную модель на всем `train_data`, а на `test_data` будем считать итоговое качество.\n",
        "\n",
        "Отметим, что для моделей `sklearn` мы не можем по умолчанию использовать категориальные признаки. Поэтому мы будем использовать `train/test_one_hot_data`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IwA6nOasqked"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создадим полную матрицу объекты-признаки. Используем числовые и one-hot данные."
      ],
      "metadata": {
        "id": "SD9uwlalNtiV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_fPjJs4SqsM7"
      },
      "outputs": [],
      "source": [
        "train_data_for_forest = pd.concat([train_real_data, train_one_hot_data], axis='columns')\n",
        "test_data_for_forest = pd.concat([test_real_data, test_one_hot_data], axis='columns')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Задание\n",
        "Выберите оптимальный параметр max_depth от 3 до 19 включительно для модели случаного леса. Используйте кросс-валидацию. Для каждой глубины посчитайте среднее по фолдам значение метрики ROC-AUC и запишите получившиеся данные в массив `rf_metrics`. Используйте 5 фолдов для кросс-валидации.\n",
        "\n",
        "**Совет**. Для ускорения работы функции `cross_val_score` используйте параметр n_jobs=-1."
      ],
      "metadata": {
        "id": "gohwNoCyN0HO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qfpk4oS5q8wi"
      },
      "outputs": [],
      "source": [
        "depths = np.arange(3, 20)\n",
        "rf_metrics = []\n",
        "\n",
        "for depth in depths:\n",
        "    scores = #ВАШ КОД. Примените кросс-валидацию.\n",
        "\n",
        "    rf_metrics.append(np.mean(scores))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WICL-7QwKuxq"
      },
      "source": [
        "Построим график получившейся метрики в зависимости от параметра `depth`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vEVvBZXVsLyH"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(np.arange(3, 20), rf_metrics)\n",
        "plt.xlabel('depth')\n",
        "plt.ylabel('roc-auc-score')\n",
        "plt.grid()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sm6R8MoUKuxq"
      },
      "source": [
        "### Задание\n",
        "Выберите оптимальное значение глубины и обучите для этого значения единственную модель `RandomForestClassifier` на всех обучающих данных `train_data_for_forest`. Предскажите вероятность класса 1 на обучающих и тестовых данных. Сохраните их в переменные `train_y_pred_forest` и `test_y_pred_forest`. Используйте метод `predict_proba`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LNUWEZpXsYB4"
      },
      "outputs": [],
      "source": [
        "best_depth = #ВАШ КОД\n",
        "\n",
        "model = RandomForestClassifier(n_estimators=100, max_depth=best_depth)\n",
        "\n",
        "#ВАШ КОД. Обучите модель\n",
        "\n",
        "\n",
        "train_y_pred_forest = #ВАШ КОД\n",
        "test_y_pred_forest = #ВАШ КОД"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RxgqJDnTKuxq"
      },
      "source": [
        "### Задание\n",
        "Вычислите ROC-AUC на обучающем и тестовом множестве."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uqihRC74tGGJ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve, roc_auc_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8WsSKFNBKuxr"
      },
      "outputs": [],
      "source": [
        "train_auc = #ВАШ КОД\n",
        "test_auc = #ВАШ КОД"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4ZBTwgUKuxr"
      },
      "source": [
        "Проверим, что мы получили достаточно хорошие значения для `test_auc`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fnJ22KZ_Kuxr"
      },
      "outputs": [],
      "source": [
        "assert test_auc > 0.90"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xzvqf4fItB2i"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(*roc_curve(y_train, train_y_pred_forest)[:2],\n",
        "         label=f'train auc={train_auc}')\n",
        "plt.plot(*roc_curve(y_test, test_y_pred_forest)[:2],\n",
        "         label=f'test auc={test_auc}')\n",
        "\n",
        "\n",
        "plt.plot([0,1], [0,1], '--', color='black')\n",
        "plt.legend()\n",
        "plt.grid()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Olu9UFhYKuxr"
      },
      "source": [
        "### Задание\n",
        "Создайте датасет `scoring_data_for_forest` и предскажите на нем целевую переменную."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CoP8jwU6Kuxr"
      },
      "outputs": [],
      "source": [
        "scoring_data_for_forest = #ВАШ КОД\n",
        "scoring_y_pred_forest = #ВАШ КОД"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5XSMDTifr7T"
      },
      "source": [
        "Сохраним scoring_y_pred_forest. Отправьте их на Stepik, полностью скопировав содержимое файла и вставив их вместо \"<ВАШ КОД. Вставьте сюда list вероятностей, предсказанных случайным лесом на data_scoring.csv>\" так, чтобы переменная answer содержала список вероятностей в нужном порядке."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('scoring_y_pred_forest.txt', \"w\") as f:\n",
        "    f.write(', '.join([str(item) for item in scoring_y_pred_forest]))"
      ],
      "metadata": {
        "id": "h8mqhKf7dVyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для посылки на kaggle обычно используют функцию `.to_csv`, как ниже, но нам этот код не понадобится:"
      ],
      "metadata": {
        "id": "-8dD_JxQfXM5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5P7OGdIEfr7Z"
      },
      "outputs": [],
      "source": [
        "pd.Series(scoring_y_pred_forest).to_csv('scoring_y_pred_forest.csv', header=None, index=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RqoeqkJuR2g"
      },
      "source": [
        "## Часть 3. Обучение градиентного бустинга\n",
        "Мы будем использовать библиотеку Catboost. Catboost --- это библиотека для градиентного бустинга от компании Яндекс. Она, как следует из названия, отличается удобной работой с данными вообще и категориальными признаками с частности. Про Catboost можно прочитать в [официальной документации](https://catboost.ai/en/docs/concepts/python-usages-examples) и в статье на [Хабре](https://habr.com/ru/post/599827/).\n",
        "\n",
        "<img src=\"https://avatars.mds.yandex.net/i?id=53d991f7cac35c76bf747793019c39fb-3751806-images-thumbs&n=13&exp=1\" style=\"height:400px; width:800px\">\n",
        "\n",
        "Обратите внимание на следующие моменты:\n",
        "* В Catboost можно сразу передавать категориальные признаки без предварительного кодирования.\n",
        "* В Catboost для категориальных признаков необходимо заполнять пропущенные значения. Мы будем заполнять их значениями `'unknown'`.\n",
        "* Для работы с данными в Catboost [есть специальный класс](https://catboost.ai/en/docs/concepts/python-reference_pool), который называется `Pool`. Прочитать о нем можно также в [примерах использования](https://catboost.ai/en/docs/concepts/python-usages-examples).\n",
        "* Для кросс-валидации в Catboost [есть специальный класс](https://catboost.ai/en/docs/concepts/python-reference_cv) `cv`. Об использовании можно прочитать в статье на [Хабре](https://habr.com/ru/post/599827/).\n",
        "* Собственно, основная модель для классификации в Catboost --- это `CatBoostClassifier`.\n",
        "\n",
        "Для установки `catboost` вы можете выполнить следующую команду."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qs35kLJPKuxs"
      },
      "outputs": [],
      "source": [
        "!pip install catboost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqEuErm7Kuxs"
      },
      "source": [
        "Импортируем все необходимые классы."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BrYDQ_tNuWmg"
      },
      "outputs": [],
      "source": [
        "from catboost import CatBoostClassifier, Pool, cv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPOVS9IuKuxs"
      },
      "source": [
        "### Задание\n",
        "Заполните пропуски в данных `train_cat_data` и `test_cat_data` значением `'unknown'`. Используйте метод `fillna`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CfdxlQxDKuxt"
      },
      "outputs": [],
      "source": [
        "train_cat_data = #ВАШ КОД\n",
        "test_cat_data = #ВАШ КОД"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9oWzO7hfKuxt"
      },
      "source": [
        "### Задание\n",
        "Создайте новые наборы данных для train и test, состоящие из `[train/test]_real_data` и `[train/test]_cat_data`. Используйте `pd.concat`. Затем создайте обучающий и тестовый `Pool` (за вас мы выделили номера категориальных признаков)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nVnooXSBvET_"
      },
      "outputs": [],
      "source": [
        "train_data_for_boosting = #ВАШ КОД. Используйте pd.concat\n",
        "test_data_for_boosting = #ВАШ КОД. Используйте pd.concat\n",
        "\n",
        "cat_features = np.arange(train_cat_data.shape[1]) + train_real_data.shape[1]\n",
        "\n",
        "train_dataset = Pool(data=train_data_for_boosting,\n",
        "                     label=y_train,\n",
        "                     cat_features=cat_features)\n",
        "\n",
        "test_dataset = # ВАШ КОД. Сделайте то же самое для test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RnFK5vH-Kuxt"
      },
      "source": [
        "Для каждого значения depth от 3 до 16 включительно используйте функцию `cv` для подсчета результатов кросс-валидации. Затем посчитайте среднее по фолдам значение метрики ROC-AUC с последней итерации и запишите получившиеся данные в массив `boosting_metrics`.\n",
        "\n",
        "Обратите внимание, что функция `cv` должна принимать следующие параметры:\n",
        "* `pool` (используйте `train_dataset`)\n",
        "* `params` (используйте параметры, указанные в коде)\n",
        "* `fold_count` (положите равным 5).\n",
        "\n",
        "Функция cv возвращает pd.DataFrame с метриками обучения. Вам понадобится колонка `'test-AUC-mean'` и последняя строчка. Обратите внимание, что обучение занимает значительное время! Сначала можете попробовать выполнить этот код для небольшого массива `depths`, чтобы было легче дебагать."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MwGJepyuxOmc",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "depths = np.arange(3, 17)\n",
        "boosting_metrics = []\n",
        "\n",
        "for depth in depths:\n",
        "    params = {\"iterations\": 100,\n",
        "              \"depth\": depth,\n",
        "              \"loss_function\": \"Logloss\",\n",
        "              \"custom_loss\": \"AUC\",\n",
        "              \"verbose\": False}\n",
        "\n",
        "    scores = #ВАШ КОД. Используйте функцию cv\n",
        "\n",
        "    boosting_metrics.append(<ВАШ КОД>)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4zJBJmvKuxt"
      },
      "source": [
        "Построим график получившейся метрики в зависимости от параметра `depth`. Сравним его с тем же графиком для метрик случайного леса."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IX1YIHmFvPH0"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(np.arange(3, 20), rf_metrics, label='Random Forest AUC')\n",
        "plt.plot(np.arange(3, 17), boosting_metrics, label='Catboost AUC')\n",
        "plt.xlabel('depth')\n",
        "plt.ylabel('roc-auc-score')\n",
        "plt.grid()\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYAZAjlgKuxv"
      },
      "source": [
        "Ответье на следующие вопросы:\n",
        "* Для какой модели общие результаты получились лучше? Если лучше результаты получились у бэггинга, как вы думаете, получится ли у бустинга отыграться на полной выборке и при большем количестве деревьев?\n",
        "* Какова получилась оптимальная глубина для бустинга?\n",
        "* Как она отличается от оптимальной глубины для бэггинга?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0slj4Xf-Kuxv"
      },
      "source": [
        "### Задание\n",
        "Мы нашли оптмальную глубину. Обучите для этого значения глубины один `CatBoostClassifier` со следующими параметрами:\n",
        "* `iterations=500` (именно 500, потому что качества с сотней деревьев может не хватить!)\n",
        "* `depth =` глубина, которую вы нашли\n",
        "* `loss_function='Logloss'`\n",
        "* `verbose=False` (чтобы не было лишнего вывода).\n",
        "\n",
        "Обучение производится с помощью метода `fit`, который принимает единственный аргумент --- `Pool` с данными. В данном случае используйте `train_dataset`.\n",
        "\n",
        "Предскажите значения на `train_dataset` и `test_dataset`. Это делается методом `predict_proba` (устроен так же, как и в `sklearn`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2ts0N0Pv6Qj"
      },
      "outputs": [],
      "source": [
        "best_depth = #ВАШ КОД\n",
        "\n",
        "model = #ВАШ КОД. Создайте объект класса CatBoostClassifier\n",
        "\n",
        "#ВАШ КОД. Обучите модель на train_dataset\n",
        "\n",
        "\n",
        "train_y_pred_boosting = #ВАШ КОД. Используйте predict_proba\n",
        "test_y_pred_boosting = #ВАШ КОД. Используйте predict_proba"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJNQm4N_Kuxw"
      },
      "source": [
        "### Задание\n",
        "Вычислите ROC-AUC на обучающем и тестовом множестве."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NwJ0z3n-Kuxw"
      },
      "outputs": [],
      "source": [
        "train_auc = #ВАШ КОД\n",
        "test_auc = #ВАШ КОД"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gaF0m2MdKuxw"
      },
      "source": [
        "Проверим, что мы получили достаточно хорошие значения для `test_auc`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ru1G2hJOKuxw"
      },
      "outputs": [],
      "source": [
        "assert test_auc > 0.915"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51GQFZ30Kuxw"
      },
      "source": [
        "Построим ROC-кривые для получившейся модели."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XMEBrLhzwyaA"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(*roc_curve(y_train, train_y_pred_boosting)[:2],\n",
        "         label=f'train auc={train_auc}')\n",
        "plt.plot(*roc_curve(y_test, test_y_pred_boosting)[:2],\n",
        "         label=f'test auc={test_auc}')\n",
        "\n",
        "plt.plot([0,1], [0,1], '--', color='black')\n",
        "\n",
        "plt.legend()\n",
        "plt.grid()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGsllxMCKuxw"
      },
      "source": [
        "### Задание\n",
        "Примените построенную модель к данным `scoring_data`. Для этого повторите все шаги, которые вы делали с тестовыми данными:\n",
        "* Заполнение пропущенных значений\n",
        "* Конкатенация числовых и категориальных данных\n",
        "* Создание `scoring_dataset` (здесь не нужно передавать аргумент `label`, так как мы их не знаем)\n",
        "* Предсказание вероятностей 1 класса"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cyTsaF1EKuxx"
      },
      "outputs": [],
      "source": [
        "#ВАШ КОД\n",
        "scoring_y_pred_boosting = #ВАШ КОД. Сохраните вероятности, предсказанные моделью"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4JwH8r7Kuxx"
      },
      "source": [
        "Сохраним предсказанные значения. Отправьте их на Stepik."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lfW8H_CsKuxx"
      },
      "outputs": [],
      "source": [
        "with open('scoring_y_pred_boosting.txt', \"w\") as f:\n",
        "    f.write(', '.join([str(item) for item in scoring_y_pred_boosting]))"
      ]
    }
  ]
}